Plateforme **HIDOOP**
=======================  
![Language Java](https://img.shields.io/badge/Langage-Java-B07219)
![Platform Linux](https://img.shields.io/badge/Platforme-Linux-red)

**Hidoop est une plateforme destin√©e √† l'ex√©cution d'applications distribu√©es sur des clusters de machines.**

Le fonctionnement est inspir√© de celui de [Hadoop](https://hadoop.apache.org/). La plateforme comporte deux modules :
* üìÇ **Un syst√®me de fichiers distribu√©** (HDFS)
* üöÄ **Une impl√©mentation du sch√©ma MapReduce** pour le calcul de donn√©es massives

Pour commencer üìç
----------------  

### Pr√©requis
- L'application fonctionne sur Linux et utilise un terminal **bash**
- Toutes les machines doivent √™tre accessibles depuis le client via **SSH**
- L'application utilise **Java** (> 1.8)

### Installation
Pour commencer, d√©finir une variable d'environnement **HIDOOP_HOME** (pointant sur le r√©pertoire qui sera utilis√© par hidoop) sur chaque machine o√π tournera l'application.  
‚úè Les classes sont consid√©r√©es comme √©tant dans **$HIDOOP_HOME/src** par d√©faut, mais il est possible de d√©finir une variable d'environnement **HIDOOP_CLASSES** qui indique la localisation des classes java de l'application.

### Configuration de Hidoop

La configuration se fait via un fichier unique *conf.xml* plac√© dans le r√©pertoire **$HIDOOP_HOME/config/** de la machine cliente.  
Un fichier d'exemple est donn√© ci-dessous :
```xml  
<?xml version="1.0" encoding="UTF-8"?>  
<config metadata="meta">  
 <default-chunk-size value="64" unit="bytes" /> 
 <servers> 
    <node ip="127.0.0.1"/> 
    <node ip="chewie"/> 
    <node ip="yoda"/> 
 </servers>
</config>  
```  

- **config** : l'attribut obligatoire _metadata_ est le nom du fichier de m√©tadonn√©es qui sera cr√©√©.
  * **default-chunk-size** : √©l√©ment optionnel pr√©cisant la taille de chunk (entier) √† utiliser par d√©faut dans HDFS. Si absent, cette taille est de 64MB.  
    ‚úè Les unit√©s de tailles support√©es sont bytes, kB, MB, GB (non sensible √† la casse). Par simplicit√©, une unit√© inconnue a le m√™me effet que bytes.

  *  **servers** : liste des serveurs. L'attribut _ip_ d'un _node_ correspond soit √† l'adresse ip de la machine soit √† son nom (hostname). Cette liste ne peut pas √™tre vide.

Utilisation de la plateforme üìö
-----------------------  

La plateforme s'utilise via le script ***hidoop***.  
Commande : `$ ./hidoop <ssh_username>`

Au d√©marrage, ce shell charge le contenu du fichier de configuration *conf.xml*. Il permet d'interagir avec les machines du cluster via SSH.


### Initialisation et d√©ploiement
Les commandes sont lanc√©es sur la machine cliente apr√®s avoir clon√© le projet dans **$HIDOOP_HOME** et cr√©√© le fichier de configuration.  
On utilise le shell `hidoop-deploy` (accessible via la commandes `deploy`) qui permet d'automatiser le d√©ploiement de la plateforme.

```shell  
$ ./$HIDOOP_HOME/hidoop $USER
hidoop> deploy  
hidoop-deploy> mkhome ; tonodes $NODES ; compile 
hidoop-deploy> exit  
hidoop>  
```  

Ici, on lance l'application en utilisant le nom d'utilisateur courant pour les connections en SSH.  
Dans le shell de d√©ploiement, on commence par cr√©er si n√©cessaire le dossier d√©fini dans **HIDOOP_HOME** sur les serveurs distants,  puis on envoie l'application sur l'ensemble des serveurs. Enfin on compile l'application sur la machine cliente locale.

#### Detail des commandes

- `compile` pour compiler l'application localement
- `tonode <server1> [ <server2> ... ]` pour d√©ployer sur les serveurs distants pass√©s en argument
- `mkhome` pour cr√©er les r√©pertoires **$HIDOOP_HOME** sur les serveurs o√π ils n'existent pas
- `rmhome <server1> [ <server2> ... ]` pour effacer le r√©pertoire **$HIDOOP_HOME** et son contenu (donn√©es, fichiers de log, etc.) sur les serveurs pass√©s en argument (utile pour supprimer d√©finitivement l'application d'une machine)
- `rmnodedata <server1> [ <server2> ... ]` pour effacer seulement les donn√©es des serveurs pass√©s en argument

‚úè La variable en lecture seule **$NODES** contient la liste des serveurs configur√©s dans *conf.xml*.

### Lancement et arr√™t de la plateforme

Dans le shell de l'application `hidoop`, il est possible de lancer les commandes suivantes :
- `printconf` pour afficher le contenu de *conf.xml*
- `start` pour lancer la plateforme
- `stop` pour arr√™ter la plateforme
- `restart` pour recharger la liste des serveurs d√©finis dans *conf.xml* et relancer la plateforme
- `exit` pour sortir du shell et arr√™ter la plateforme

‚ö† En cas de changement de configuration, seule la commande `restart` permet de recharger le contenu du fichier.

### Gestion des fichiers dans HDFS
‚ö† Les commandes suivantes n√©cessitent que la plateforme soit en fonctionnement.
- `hdfs -l [options]` pour lister les fichiers √©crits dans HDFS.  
    Options :
    * `--detail` pour des informations sur les chunks

- `hdfs -w <localfilename> [options]` pour √©crire un fichier dans HDFS  
  `<localfilename>` peut √™tre un chemin absolu ou relatif √† **$HIDOOP_HOME/data/**.  
  Le fichier √©crit dans HDFS aura le nom du fichier local.  
    Options :
    * `-f ln|kv` format du fichier (ln par d√©faut)
    * `--chunks-size=<taille>` taille des chunks (ex : 100MB, 3kB...). Si aucune unit√© (B, kB, MB, GB, TB) n'est fournie, la valeur est en bytes. Si la valeur est n√©gative, cet argument est ignor√©.
    * `--rep=<factor>` facteur de r√©plication des chunks (entier positif)

- `hdfs -r <filename> [options]` pour lire un fichier stock√© dans HDFS vers la machine locale.  
    Options :
    * `<localfilename>` fichier local de destination. Le chemin peut √™tre absolu ou relatif √† **$HIDOOP_HOME/data/**. Le fichier est lu dans *r_&lt;filename&gt;* par d√©faut.

- `hdfs -d <filename>` pour supprimer un fichier de HDFS

#### Format des fichiers

HDFS supporte 2 formats : ***Key-Value*** (*kv*) et ***Line*** (*ln*).

- ***Line*** :

  > Ce fichier est au format ln.    
  > Les lignes ne sont jamais coup√©es,    
  > mais ne doivent pas √™tre trop longues.

  Dans ce format, les donn√©es sont √©crites ligne par ligne. Une ligne n'est jamais coup√©e lors de la fragmentation d'un fichier en chunks.   
  La longueur des lignes ne doit donc pas √™tre trop disparate. Si pour un fichier, une ligne d√©passe 2 fois la taille d'un chunk, le fichier ne pourra pas √™tre √©crit.



- ***Key-Value*** :

  > ville<->Toulouse    
  > √©cole<->N7    
  > ann√©e<->2

  Dans ce format, les donn√©es sont √©crites avec une paire cl√©/valeur (s√©par√©es par "<->") par ligne. Une ligne n'est jamais coup√©e lors de la fragmentation d'un fichier en chunks.

### Lancement des applications MapReduce
‚ö† Les commandes suivantes n√©cessitent que la plateforme soit en fonctionnement.

La commande `launch <appname> [options] <filename>` permet de lancer une application de calcul MapReduce.  
Options :
* `-ip <address>` : l'impl√©mentation du MapReduce utilisant Java RMI, il peut √™tre n√©cessaire de pr√©ciser quelle adresse ip transmettre depuis la JVM du client. 

‚úè `launch MyMapReduce [options] <filename>` ex√©cute l'application de comptage de mots ***MyMapReduce*** sur un fichier enregistr√© dans HDFS.  
Le fichier de r√©sultats se nomme *&lt;filename&gt;-tot* et est au format *kv*.


### Supervision et √©valuation

Dans le shell `hidoop-monitoring` (accessible via la commandes `monitoring`), on peut utiliser les commandes classiques de l'application et superviser l'application en plus des commandes suivantes :
- `cmpref <file>` pour comparer un r√©sultat de mmr avec sa version s√©quentielle sur un fichier
- `evalf <fromN> <toN> <file>` pour √©valuer les performances sur un fichier selon le nombre de chunks
- `logtail <servername>` pour afficher les derni√®res lignes de log d'un serveur distant
- `nodels <servername>` pour lister les fichiers de donn√©es d'un serveur distant
- `logrm <servername>` pour effacer les logs d'un serveur distant

Le fonctionnement de Hidoop üñ•
--------------------------  

L'application se base sur les interactions entre une machine cliente principale et des serveurs distants qui effectuent le stockage des donn√©es et les calculs.

### HDFS
Sur la machine cliente, un daemon *NameNode* tourne en arri√®re-plan. Il g√®re la configuration de la plateforme, l'acc√®s aux serveurs et la localisation des chunks des fichiers HDFS (m√©tadonn√©es).  
Le client communique avec le *NameNode* localement via RMI.

Les requ√™tes HDFS utilisent des Sockets TCP pour communiquer avec les serveurs d√©sign√©s par le *NameNode*.

Lorsqu'un fichier est ajout√© √† HDFS, il est d√©coup√© en morceaux (chunks) et r√©parti sur les diff√©rents serveurs disponibles.

### Applications MapReduce

Les applications de MapReduce utilisent RMI avec les serveurs distants pour lancer les calculs sur chaque chunk (phase Map) puis r√©cup√®rent les r√©sultats interm√©diaires et les combinent (phase Reduce).

### Developpement

Thomas Guillaud - 
Axel Grunig -
Nathan Razafimanantsoa -
Chloe Laplagne